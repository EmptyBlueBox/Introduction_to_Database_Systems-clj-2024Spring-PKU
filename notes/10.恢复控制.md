# 第十章 恢复控制

## 故障类型

事务故障: 单个事务的运行没有到达预期的终点就被中止

事务故障:

1. 非预期故障: 不能由事务程序处理的如运算溢出，发生死锁而被选中撒诮该事务
2. 可预期故障: 应用程序可以发现的事务故障，并且应用程序可以让事务回滚, 如转帐时发现帐面金额不足

系统故障:

1. 软故障（soft crash）
2. 在硬件故障、软件错误的影响下，虽引起**内存信息丢失**，但未破坏外存中数据
3. 如CPU故障、突然停电DBMS, OS，应用程序等异常终止

介质故障:

1. 硬故障（hard crash）
2. 又称磁盘故障，**破坏外存**上的数据库，并影响正在存取这部分数据的所有事务
3. 如磁盘的磁头碰撞瞬时的强磁场干扰

### 服务可用性、数据一致性之间的矛盾

如果有一个分布式系统, 连接断开, 这两个性质只能满足一个了

### 冗余

冗余 = 备份＋日志

备份: 数据副本

日志: 事务活动副本

## 备份

将数据库复制到磁带或另一个磁盘上保存起来的过程

这些备用数据称为后备（后援）副本

转储类型:

1. 静态转储
   1. 转储期间不允许对数据库进行任何存取、修改活动
2. 动态转储
   1. 一般采用这个, 但是需要同时进行备份和日志
   2. 转储期间允许对数据库进行存取或修改
3. 海量转储
   1. 每次转储全部数据库
4. 增量转储
   1. 每次只转储上次转储后更新过的数据

### 数据库备份

以下略去:

SQLServer

差异数据库备份（DCM）： SQLServer

MySQL备份类型

## 日志

日志文件是以事务为单位用来记录数据库的每一次更新活动的文件，由系统自动记录

日志内容包括：记录名、旧记录值、新记录值、事务标识符、操作标识符等

* 事务T开始时，写入日志：<Ti start＞
* 事务Ti执行write（X）前，写入日志：<Ti, X，V1, V2>V是X更新前的值（前像），V是X更新后的值（后像）
* 事务Ti结束后，写入日志； < Ti commit >

### 日志的生成

<img src="./10.恢复控制.assets/CleanShot 2024-06-09 at 02.33.55@2x.png" alt="CleanShot 2024-06-09 at 02.33.55@2x" style="zoom:50%;" />

### 基于日志记录的事务分类

圆满事务：日志文件中记录了事务的commit标识

天折事务：日志文件中只有事务的begin标识，无commit

<img src="./10.恢复控制.assets/CleanShot 2024-06-09 at 02.34.26@2x.png" alt="CleanShot 2024-06-09 at 02.34.26@2x" style="zoom:50%;" />

### 基本的恢复操作

对圆满事务的更新日志执行redo操作，即重新执行该操作, 修改对象被赋予新记录值, 具有幂等性：$redo = redo^2$​​

<img src="./10.恢复控制.assets/CleanShot 2024-06-09 at 02.37.46@2x.png" alt="CleanShot 2024-06-09 at 02.37.46@2x" style="zoom:50%;" />

对天折事务的更新日志执行undo操作，即撤销执行该操作, 修改对象被赋予旧记录值, 具有幂等性：$undo =undo^2$

<img src="./10.恢复控制.assets/CleanShot 2024-06-09 at 02.37.51@2x.png" alt="CleanShot 2024-06-09 at 02.37.51@2x" style="zoom:50%;" />

### 其他日志恢复技术：提交日志 (Commit Logging)

只需要记录后项, 只能做 redo

* 脏数据不会持久化
* 只有redo记录，没有undo记录
* 提交时将事务日志都刷写到磁盘

细节:

* 事务提交之前，其修改结果不会写入磁盘
* 日志中没有提交标记的事务，其修改结果没有写盘
* 恢复时只需重做日志中的提交事务
* OceanBase、Hekaton（SQL Server 内存存储引擎）

### 无日志恢复技术：Shadow Paging

* 被修改的数据会同时存在两份，一份修改前的数据，一份是修改后的数据，称为影子（Shadow）
* 系统通过两个目录结构分别指向修改前的数据和修改后的数据，最后Current 指针原子切换到新的目录上，表示事务提交成功
* 当事务提交时，以一次原子数据写入让整个事务新的修改生效
* 如果在事务提交前出现系统故障，数据库恢复时见不到未完成事务的修改，硬盘上的这个事务曾经修改的数据也会由垃圾回收模块回收
* 持久性保证：事务的修改直接持久化在硬盘上，无需日志支持

<img src="./10.恢复控制.assets/CleanShot 2024-06-09 at 02.43.17@2x.png" alt="CleanShot 2024-06-09 at 02.43.17@2x" style="zoom:50%;" />

类似 GitHub 本地和远程仓库

### 事务日志备份例子

<img src="./10.恢复控制.assets/CleanShot 2024-06-09 at 02.54.54@2x.png" alt="CleanShot 2024-06-09 at 02.54.54@2x" style="zoom:50%;" />

第一个恢复代码是对的.

因为 MyDB_log1 中还没有 commit, 不应该做回滚的操作, 所以对于 MyDB_log1 应该使用 norecovery

### 简单恢复模型

允许将数据库恢复到最新的备份

### 完全恢复

允许将数据库恢复到故障点状态

### 大容量日志记录恢复

只保存语句, 前后项的数据保存在别的地方

允许大容量日志记录操作（bulk insert...）

数据库备份 + 差异备份（可选）＋事务日志备份

## WAL

### 回顾：事务中的数据访问原语

区分 read 和 input ?

<img src="./10.恢复控制.assets/CleanShot 2024-06-09 at 03.14.18@2x.png" alt="CleanShot 2024-06-09 at 03.14.18@2x" style="zoom:50%;" />

### 先写日志的原则

<img src="./10.恢复控制.assets/CleanShot 2024-06-09 at 03.15.10@2x.png" alt="CleanShot 2024-06-09 at 03.15.10@2x" style="zoom:50%;" />

日志记录将要发生何种修改, 写入DB表示实际发生何种修改

Write Ahead Log: 对于尚未提交的事务，在将DB缓冲区写到外存之前，必须先将日志缓冲区内容写到外存去

什么不能先写数据库？如果先写DB，则可能在写的中途发生系统崩溃，导致内存缓冲区内容丢失，而外存DB处于不一致状态，由于日志缓冲区内容己破坏，导致无法对DB恢复

<img src="./10.恢复控制.assets/CleanShot 2024-06-09 at 03.20.32@2x.png" alt="CleanShot 2024-06-09 at 03.20.32@2x" style="zoom:50%;" />

WAL就可以保证恢复的一致性吗？

第一种情况:

<img src="./10.恢复控制.assets/CleanShot 2024-06-09 at 03.20.55@2x.png" alt="CleanShot 2024-06-09 at 03.20.55@2x" style="zoom:50%;" />

第二种情况:

<img src="./10.恢复控制.assets/CleanShot 2024-06-09 at 03.21.54@2x.png" alt="CleanShot 2024-06-09 at 03.21.54@2x" style="zoom:50%;" />

### 日志缓冲区和数据库缓冲区的写时机不同

日志很重要, 一定要确认了再告诉用户已经 commit

同步（Synchronous）写日志：只有事务的相关日志已经完全在磁盘上了，才会向进程发送该事务已提交的确认消息

异步（asynchronous）写缓冲区：只需要将数据页的写入操作投递给操作系统即可，不需要等待其完成

### 读取一个页面的过程

<img src="./10.恢复控制.assets/CleanShot 2024-06-09 at 03.24.14@2x.png" alt="CleanShot 2024-06-09 at 03.24.14@2x" style="zoom:50%;" />

### MySQL日志刷写时机

在主线程每秒一次的循环中，将重做日志缓冲器的内容刷新到重做日志文件中，即便某个事务尚未提交

由参数innodb_flush_log_at_trx_commit控制

* 0代表提交事务时，并不立即刷出日志，而是等待主线程每秒的刷新
* 1代表提交事务时，将重做日志同步写磁盘，也即伴有 fsync() 的调用
* 2代表提交事务时，将重做日志异步写磁盘，也即写入文件系统缓存中

<img src="./10.恢复控制.assets/CleanShot 2024-06-09 at 03.26.51@2x.png" alt="CleanShot 2024-06-09 at 03.26.51@2x" style="zoom:50%;" />

fsynC是昂贵操作，MySQL一次事务提交最多会导致3次fsync组提交：将多个并发提交的事务共享一次fsync操作

binlog_group_commit_sync_delay = N: 在等待N微秒后，进行binlog刷盘操作

binlog_group_commit_sync_no_delay_count = N: 达到最大事务等待数量，开始binlog刷盘

## 故障恢复

### 事务故障恢复

* 反向扫描日志文件，查找该事务的更新操作
* 对事务更新操作执行undo操作，即将事务更新前的旧值写入数据庫
* 继续反向扫描日志文件，查找该事务的其他更新操作，并做同样处理
* 直至读到事务的开始标识，结束事务故障恢复过程

为什么同一事务的日志记录需要反向键接在一起？加快撤销速度

<img src="./10.恢复控制.assets/CleanShot 2024-06-09 at 03.30.52@2x.png" alt="CleanShot 2024-06-09 at 03.30.52@2x" style="zoom:50%;" />

事务故障恢复中多什么要反向undo ？

<img src="./10.恢复控制.assets/CleanShot 2024-06-09 at 03.31.31@2x.png" alt="CleanShot 2024-06-09 at 03.31.31@2x" style="zoom:50%;" />

### 系统故障恢复

不一致状态原因:

* 未完成事务对数据库的更新已写入数据库
* 已提交事务对数据库的更新未写入数据库

系统故障恢复过程

* 正向扫描日志文件，将圆满事务记入重做队列，将天折事务记入撤消队列
* 反向扫描日志，对撒消队列中事务Ti的每一个日志记录执行undo操作
* 正向扫描日志文件，对重做队列中事务Ti的每一个日志记录执行redo操作

<img src="./10.恢复控制.assets/CleanShot 2024-06-09 at 03.40.13@2x.png" alt="CleanShot 2024-06-09 at 03.40.13@2x" style="zoom:50%;" />

### 介质故障恢复

磁盘上数据文件和日志文件遭到破坏

介质故障恢复过程

* 装入最新的数据庫后备副本，使数据库恢复到最近一次转储时的一致性状态
* 装入相应的日志文件副本，重做已完成的事务

<img src="./10.恢复控制.assets/CleanShot 2024-06-09 at 03.41.29@2x.png" alt="CleanShot 2024-06-09 at 03.41.29@2x" style="zoom:50%;" />

## 检查点

当系统故障发生时，我们必须搜索整个日志，以决定哪些事务需要redo，哪些需要undo

大多数需要被重做的事务其更新已经写入了数据库中（$redo^2$）, 尽管对它们重做不会造成不良后果，但会使恢复过程变得更长

* 保证在检查点时刻磁盘上日志文件与数据库的内容是一致的
* 确保检查点时刻提交事务的结果已经写入数据库了

### 检查点在系统故障恢复中的作用

<img src="./10.恢复控制.assets/CleanShot 2024-06-09 at 03.43.27@2x.png" alt="CleanShot 2024-06-09 at 03.43.27@2x" style="zoom:50%;" />

从最早的活跃事物开始恢复

所以长事务对数据库的恢复影响很大

### 一致性检查点 Consistent Checkpoint

一致性检查点是最朴素的实现，步骤如下：

1. 停服：禁止新事务启动，等待正在执行的事务结束
2. 遍历Buffer Pool，将所有Dirty Page刷盘
3. 记录一条Checkpoint Log
4. 恢复服务：允许所有事务正常执行
   1. Recovery直接从Checkpoint Log开始，之前的Log一律跳过

### 模糊检查点 Fuzzy Checkpoint

脏页: 修改这个页的事务还没有提交

1. 记录一条 Checkpoint Begin Log
2. 输出活跃事务列表ATT和脏页表DPT
3. 记录一条Checkpoint End Log，包括ATT和DPT，然后把Log刷盘
4. 把Checkpoint Begin Log的LSN信息记录到Master Record中

Master Record：磁盘上的一个文件，记录最近一次Checkpoint Log的LSN。通过它可以快速定位最近一次Checkpoint的Log

#### 如何处理检意点生成过程中重复变脏的页面？

* 在模糊检查点生成过程中，已经刷盘的页面，可能又被事务修改
* 对于在检查点期间新近引入的页面，或者已经被检查点输出到磁盘但又重新变脏的页面，都不会被该次检查点操作写入
* 为避免在一次检查点生成过程中重复将页面写入磁盘，为每个页面设置标志位，开始时所有的位都相同（都为0或1）
* 当检查点检查到某个页面时，它将其标志位翻转，直接跳过标志位相反的页面

#### 如何快速完成检查点生成过程中的写盘动作？

* 尽量保证磁盘页的写入是连续的
* 缓冲区中非连续页面可以被一次聚集写入（gather-write）磁盘
* 检查点线程按照缓冲区编号顺序扫描页面，当发现脏页时，检查与该页在磁盘上连续的其他页面是否也是脏的
* 假如它看到页面5是脏的，它可能会写入页面10、25、38、500等，这些页面在磁盘上是连续的

### 最小恢复日志序列号 (MinLSN)

MinLSN是下面这些LSN中的最小LSN：

* 检查点起点的 LSN
* 最老的活动事务起点的 LSN

<img src="./10.恢复控制.assets/CleanShot 2024-06-09 at 03.54.30@2x.png" alt="CleanShot 2024-06-09 at 03.54.30@2x" style="zoom:50%;" />

### MinLSN与物理日志文件

<img src="./10.恢复控制.assets/CleanShot 2024-06-09 at 03.55.09@2x.png" alt="CleanShot 2024-06-09 at 03.55.09@2x" style="zoom:50%;" />

［逻辑日志始端 → MinLsn］：可截断部分, 打错字了

## 复制

### 复制的优点

读写分离、伸缩性、可靠性

### 数据复制的更新传播策略

紧密复制（Eager Rephication）: 将所有结点上的复本更新作为一个原子事务的一部分，所有结点上的复本严格同步

<img src="./10.恢复控制.assets/CleanShot 2024-06-09 at 04.01.00@2x.png" alt="CleanShot 2024-06-09 at 04.01.00@2x" style="zoom:50%;" />

紧密复制（Eager Rephication）: 将所有结点上的复本更新作为一个原子事务的一部分，所有结点上的复本严格同步

<img src="./10.恢复控制.assets/CleanShot 2024-06-09 at 04.01.06@2x.png" alt="CleanShot 2024-06-09 at 04.01.06@2x" style="zoom:50%;" />

### 数据复制的更新控制策略

主方式（master）: 每一对象都拥有一个主结点，只有主结点能够更新对象的主拷贝，其它复本是只读的。其宅欲更新该对象的结点请求主结点完成更新，由主结点将更新传向其它结点

<img src="./10.恢复控制.assets/CleanShot 2024-06-09 at 04.02.06@2x.png" alt="CleanShot 2024-06-09 at 04.02.06@2x" style="zoom:50%;" />

群方式（group）: 任何拥有某数据项拷贝的结点都可以更新该拷贝，称之为随处更新 (update anywhere), 并将更新操作广播到其它结点

<img src="./10.恢复控制.assets/CleanShot 2024-06-09 at 04.02.13@2x.png" alt="CleanShot 2024-06-09 at 04.02.13@2x" style="zoom:50%;" />

### 数据复制类型

<img src="./10.恢复控制.assets/CleanShot 2024-06-09 at 04.02.24@2x.png" alt="CleanShot 2024-06-09 at 04.02.24@2x" style="zoom:50%;" />

## 镜像数据库

<img src="./10.恢复控制.assets/CleanShot 2024-06-09 at 04.04.05@2x.png" alt="CleanShot 2024-06-09 at 04.04.05@2x" style="zoom:50%;" />

## ARIES恢复算法

ARIES恢复算法中的协同概念

### 缓冲区的BM实现策略

考虑是否允许脏写和是否需要提交写, 产生四种设置

<img src="./10.恢复控制.assets/CleanShot 2024-06-09 at 04.08.53@2x.png" alt="CleanShot 2024-06-09 at 04.08.53@2x" style="zoom:50%;" />

BM不同实现技术路线的性能对比:

<img src="./10.恢复控制.assets/CleanShot 2024-06-09 at 04.09.11@2x.png" alt="CleanShot 2024-06-09 at 04.09.11@2x" style="zoom:50%;" />

所以ARIES是允许脏页落盘, 提交不要求一定落盘, 运行时很快, 恢复很慢.

### 日志类型

<img src="./10.恢复控制.assets/CleanShot 2024-06-09 at 04.10.41@2x.png" alt="CleanShot 2024-06-09 at 04.10.41@2x" style="zoom:50%;" />

之前的: 物理日志, 记录前后都是什么

还有一种: 逻辑日志, 只记录如何变化的

两者的结合: 在每一页里面使用逻辑日志, 页整体使用物理日志

各种日志类型对比:

<img src="./10.恢复控制.assets/CleanShot 2024-06-09 at 04.12.50@2x.png" alt="CleanShot 2024-06-09 at 04.12.50@2x" style="zoom:50%;" />

<img src="./10.恢复控制.assets/CleanShot 2024-06-09 at 04.12.59@2x.png" alt="CleanShot 2024-06-09 at 04.12.59@2x" style="zoom:50%;" />

为什么需要逻辑Undo日志？

需要修改数据和索引页. 

* 传统封锁技术：事务在更新一个数据项时给它施加X锁，直至事务结束
* 如果事务T向B+树插入一项，有可能造成页面拆分，需要从根到叶都加X锁，并且保持到事务结束，并发性极低；可以采取闩锁，使锁较早释放
* 如果在事务提交前释放了闩锁，则其它事务可执行插入或删除操作，造成对B+树结点的进一步改变
* 如果使用物理undo执行事务回滚，也即将B+树内部结点（执行插入操作前）的旧值写回，那么其它事务在其后执行的插入或删除操作可能会丢失

### ARIES算法遵循的一些原则

1. ARIES遵循"WAL”原则
2. ARIES使用模糊检查点
3. ARIES的BM遵循"Non - Force, Steal”
4. ARIES使用Page- oriented级的Redo, 使用Logical级的Undo

### ARIES恢复算法中的数据结构

日志结构及类型、页面结构、脏页表、活动事务列表

#### 日志结构

<img src="./10.恢复控制.assets/CleanShot 2024-06-09 at 04.37.40@2x.png" alt="CleanShot 2024-06-09 at 04.37.40@2x" style="zoom:50%;" />

#### 补偿日志

补偿日志CLR:Compensation Log Record

* ARIES中的Logical Undo操作不具有幂等性，不可以重复执行
* CLR把一条Logical Undo log进行物化，也即生成一个Page-oriented级的Redo Log，通过更改页面来达到Undo的效果
* CLR是Redo-Only的，保证已经Undo了的操作不会再被Undo

思考：为什么 ARIES 要Logging changes during undo ？

<img src="./10.恢复控制.assets/CleanShot 2024-06-09 at 04.39.29@2x.png" alt="CleanShot 2024-06-09 at 04.39.29@2x" style="zoom:50%;" />

UndoNext LSN：只在CLR中出现，用来指示下一条需要Undo的Log的LSN，也即UndoNxtLSN是当前日志正在补偿的日志记录的PrevLSN值

如果Undo到一半数据库挂掉后重启，在重新执行Undo时，只需先取出最后一条CLR Log的UndoNext LSN，就能继续之前的Undo工作

#### 页面结构

<img src="./10.恢复控制.assets/CleanShot 2024-06-09 at 04.40.51@2x.png" alt="CleanShot 2024-06-09 at 04.40.51@2x" style="zoom:50%;" />

思考：在恢复阶段是否需要对日志记录 42： <Tu,P,U, 1,3＞执行redo？不需要了. 因为48必然比42更晚更新这个表项, 就不用考虑42了.

#### 脏页表

<img src="./10.恢复控制.assets/CleanShot 2024-06-09 at 04.42.59@2x.png" alt="CleanShot 2024-06-09 at 04.42.59@2x" style="zoom:50%;" />

#### 活跃事务列表

<img src="./10.恢复控制.assets/CleanShot 2024-06-09 at 04.43.59@2x.png" alt="CleanShot 2024-06-09 at 04.43.59@2x" style="zoom:50%;" />

### ARIES恢复算法实现过程

三个原理、三个阶段、检查点生成方式

<img src="./10.恢复控制.assets/CleanShot 2024-06-09 at 04.45.13@2x.png" alt="CleanShot 2024-06-09 at 04.45.13@2x" style="zoom:50%;" />

#### 分析阶段

重建ATT和DPT: 活跃事务列表、脏页表

从MasterRecord获得最近一个检查点，顺序扫描所有Log，恢复出ATT和DPT

ATT：对任意一个事务Ti，如果:

* 遇到Ti的Begin Log，就把Ti 如入ATT，同时把状态设为 Undo Candidate
* 遇到Ti的 Commit Log，就把ATT 中的Ti状态设为 Committed
* 遇到Ti的 End Log，就把Ti以ATT 中移除
* 遇到Ti的其他 Log （Redo,Undo, CLR 和 Abort Log），更新Ti的 LastLSN

DPT：遇到任意 Redo Log 或 CLR，如果对应的 Page

* 不在DPT 中：将宅如入DPT，同时记录 RecLSN
* 已经在 DPT 中：无需处理

#### Redo阶段

找到脏页表中最小的日志序列号 recLSN, 对它之后的所有日志进行redo

通过重演所有没有反映在磁盘页上的动作来重复历史

Redo过程从RedoLSN开始向前扫描日志，该点之前的日志记录已经反映在磁盘数据库页上

只要找到一个update日志记录，它就执行如下动作：

* 如果该页不在脏页表中，或者该update日志记录的LSN小于脏页表中该页的RecLSN，Redo过程就跳过该日志记录
* 否则以磁盘调出该页，如果其PageLSN小于该日志记录的LSN （Log LSN > Page LSN），重做该日志记录，修改PageLSN为该日志的LSN

redo阶段为什么要重现历史（Repeating history）？

* 一个事务中的Delete操作同时删除了Table Page和Index Page中的一条数据，在数据库挂掉前只有Table Page被刷盘，并且这个事务没有提交
* 在Recovery期间，如果不Redo这个Delete操作，直接做 Logical Undo，向Table Page 和 Index Page 各自 Insert 一条数据，那么Index Page中会出现重复的数据

* 需要通过重现历史来将数据库中的数据恢复到Operation Consistency 的状态，保证后续 Logical Undo 的正确执行

#### Undo阶段

对于那些失败的事务, 也就是 crash 的时候那些活跃的事务, 对它们进行 undo

Undo过程反向扫描日志，取消所有ATT中的事务

* 找到 ATT 中最大的 Last LSN,Undo它对应的事务，Undo完成后把该事务以ATT 中移除。重复上面步骤，直到 ATT 为空
* 如果找到一个CLR，它用UndoNextLSN字段跳过一个已经Undo了的事务日志。否则，它用事务日志的PrevLSN字段查找下一个要被撤消的日志
* 每当一个update日志记录被用于撤消，Undo过程产生一个包含undo执行动作的CLR，并将CLR的UndoNextLSN设置为update 日志记录的PreLSN值

