# 第十一章 数据库存储

## 储存介质

<img src="./11.数据库存储.assets/CleanShot 2024-06-09 at 04.56.56@2x.png" alt="CleanShot 2024-06-09 at 04.56.56@2x" style="zoom:50%;" />

盘片（Platter）、磁道（track）、扇区（Sector）、柱面（Cylinder）、磁盘臂（disk arm）、读写头（read-Write head）：反转磁性物质磁化方向

### 磁盘的顺序和随机访问对比

7200rpm的希捷SATA硬盘顺序读写基本都能达到300MB/S

随机读写100IOPS，假设每次IO大小为IKB，则随机读写数据带宽为100KB/S

### 预读

prefetch, read-ahead，局都性原理

MySQL线性预读 （linear read-ahead）：是否将下一个extent预读到buffer pool中

### 廉价磁盘冗余阵列 (RAID)

Redundant Arrays of Inexpensive Disks 是一种利用大量廉价磁盘进行磁盘组织的技术

* 价格：大量廉价的磁盘比少量昂贵的大磁盘合算得多
* 性能：大量磁盘可以提高数据的并行存取
* 可靠性：冗余数据可以存放在多个磁盘上，因此一个磁盘的故障不会导致数据丢失

过去RAID是大而昂贵的磁盘的替代方法，今天使用RAID是因为它的高可靠性和高数据传输率。因此"”代表independent， 而非inexpensive

#### 高可靠性

N个磁盘组成的集合中某个磁盘发生故障的概率比特定的单个磁盘发生故障的概率高很多

假定单个磁盘的MTTF（MTTF，Mean Time To Failure）是100,000小时（约为11年），则由100个磁盘组成的阵列的MTTF是1000小时（约为41天）

所以需要冗余（Redundancy）：存储额外信息以便当磁盘故障时能从中重建

#### 镜像冗余

一个逻辑磁盘由两个物理磁盘组成

写操作在每个磁盘上执行, 如果其中一个发生故障，数据可以从另一个磁盘读出

只有第一个磁盘的故障尚未恢复，第二个磁盘也发生故障，这时才会发生数据丢失

假定一个磁盘的MTTF是100,000小时，修复时间是10小时，则镜像磁盘的MTTF是 $100,000^2/(2*10)=500*10^6$小时，约为57000年

#### 校验码冗余

<img src="./11.数据库存储.assets/CleanShot 2024-06-09 at 05.01.35@2x.png" alt="CleanShot 2024-06-09 at 05.01.35@2x" style="zoom:50%;" />

纠错码（ECC:Error-Correcting-Codes）

内存中每个字节都有一个奇偶校验位与之相连，它记录该字节中为1的比特位的总数是偶数（=0）还是奇数（=1），如果字节中有一位被破坏，则字节的ECC与存储的ECC就不会相匹配；通过ECC可以检测到所有的1位错误

#### 通过拆分提高并行

将数据拆分到多个磁盘上以提高传输率

通过并行提高性能的两种途径:

* 负载平衡多个小的存取操作（即页面存取），提高以提高这种存取操作的吞吐量
* 并行执行大的存取操作，以减少大的存取操作的响应时间

比特级拆分（Bit-level striping）:

* 将每个字节按比特分开，存储到多个磁盘上
* 对于由4个磁盘组成的阵列，将每个字节的第i个比特位和第 i+4 个比特位写到第i个磁盘上，其存取速度是单个磁盘的8倍

块级拆分 (Block-level striping):

* 对于由n个磁盘构成的阵列，文件的第i块 存放在第（i mod n）+1个磁盘上

#### RAID级别

**注意磁盘是按照块为单位访问的**

镜像提供高可靠性，拆分提供高数据传输率

通过利用与奇偶校验相结合的磁盘拆分想法，可以实现以较低成本提供冗余的方案

不同的RAID级别，具有不同的代价、性能和可靠性

<img src="./11.数据库存储.assets/CleanShot 2024-06-09 at 05.07.37@2x.png" alt="CleanShot 2024-06-09 at 05.07.37@2x" style="zoom:50%;" />

##### RAID 0

块级拆分且没有任何冗余的磁盘阵列, 用于高性能访问且数据丢失不十分重要的应用场合

<img src="./11.数据库存储.assets/CleanShot 2024-06-09 at 05.08.00@2x.png" alt="CleanShot 2024-06-09 at 05.08.00@2x" style="zoom:50%;" />

##### RAID 1

带块级拆分的磁盘镜像, 提供最佳写性能, 一般用于类似于数据库系统中日志文件存储的应用场合

每一份数据都有一个备份

<img src="./11.数据库存储.assets/CleanShot 2024-06-15 at 03.20.24@2x.png" alt="CleanShot 2024-06-15 at 03.20.24@2x" style="zoom:50%;" />

##### RAID 1的变种

<img src="./11.数据库存储.assets/CleanShot 2024-06-09 at 05.08.58@2x.png" alt="CleanShot 2024-06-09 at 05.08.58@2x" style="zoom:50%;" />

##### RAID 3：位交叉奇偶校验

<img src="./11.数据库存储.assets/CleanShot 2024-06-09 at 05.09.59@2x.png" alt="CleanShot 2024-06-09 at 05.09.59@2x" style="zoom:50%;" />

写操作:

<img src="./11.数据库存储.assets/CleanShot 2024-06-09 at 05.10.48@2x.png" alt="CleanShot 2024-06-09 at 05.10.48@2x" style="zoom:50%;" />

写操作需要改校验盘, 这是速度的瓶颈

注意这里不是位级拆分, 就是 RAID0 加上一个校验位

##### RAID 4

* 块级拆分，在一个独立的磁盘上为其他N个磁盘上对应的块保留一个奇偶校验块
* 读取一个块只访问一个磁盘，每个存取操作的传输率低，但可以并行地执行多个读操作，从而产生较高的总I/O率

<img src="./11.数据库存储.assets/CleanShot 2024-06-09 at 05.12.13@2x.png" alt="CleanShot 2024-06-09 at 05.12.13@2x" style="zoom:50%;" />

实际上没有RAID 4, 因为写跟RAID 3一样很慢, 但是读还是一个一个盘来的, 也不快

##### RAID 5

块级拆分, 将数据和奇偶校验位分布到所有的N个磁盘上

假设有四个磁盘 *D*1、*D*2、*D*3和*P*（奇偶校验块），数据和奇偶校验信息可以如下分布：

| 磁盘1 | 磁盘2 | 磁盘3 | 磁盘4 |
| ----- | ----- | ----- | ----- |
| D1    | D2    | D3    | P     |
| D4    | D5    | P     | D6    |
| D7    | P     | D8    | D9    |
| P     | D10   | D11   | D12   |

在这种结构中，奇偶校验块（P）是轮转存储的，即在不同的条带中，奇偶校验块的位置会变化。

特点:

* 奇偶校验块不能和这个块对应的数据存储在同一个磁盘上
* RAID 5所有磁盘都参与对读请求的服务，而RAID 4中奇偶校验磁盘不参与读操作
* RAID 5包容RAID 4，在相同成本下提供更好的读写性能

<img src="./11.数据库存储.assets/CleanShot 2024-06-09 at 05.13.35@2x.png" alt="CleanShot 2024-06-09 at 05.13.35@2x" style="zoom:50%;" />

往往要么使用RAID 1, 要么使用RAID 5

##### RAID 6

<img src="./11.数据库存储.assets/CleanShot 2024-06-09 at 05.15.46@2x.png" alt="CleanShot 2024-06-09 at 05.15.46@2x" style="zoom:50%;" />

故障恢复

<img src="./11.数据库存储.assets/CleanShot 2024-06-09 at 05.16.04@2x.png" alt="CleanShot 2024-06-09 at 05.16.04@2x" style="zoom:50%;" />

可以支持两个盘的损坏

#### 选择合适的RAID级别

RAID 1 or RAID 5?

* 依赖于读/写的比率

* 为写1块数据，RAID 5需要2块读和2块写
  * 读原来的数据和校验块
  * 写新的数据和校验块


如果应用需要每秒r次渎，w次写

* RAID 1要求每秒 r+2w 次 I/O操作
  * 适合写密集, 日志文件

* RAID 5要求每秒 r+4w 次 I/O操作
* RAID 5比RAID 1使用较少的磁盘可能是幻觉

## 缓冲区

### 缓冲区管理中的特妹内存块

被钉住的块（pinned blocks）

* 不允许写回磁盘的块
* 当一个块上的更新正在进行时，不允许写回磁盘
* 可以钉住被频繁访问的小表

块的强制刷出（forced output of blocks）

* 先写日志原则，被更新的数据页刷出时，对应的日志记录被强制刷出
* 生成检查点时，日志和数据缓冲区被强制刷出
* 提交事务时，其日志记录被强制刷出

### 缓冲区菅理：替換策略

LRU（最近最少使用）: 如果必须替换一个块，则替换最近最少使用的块

MRU（最近最常使用）: 如果必须替换一个块，则替换最近最常使用的块

#### MRU在数据库缓冲区管理中的应用场景

<img src="./11.数据库存储.assets/CleanShot 2024-06-09 at 05.20.37@2x.png" alt="CleanShot 2024-06-09 at 05.20.37@2x" style="zoom:50%;" />

### 多大缓冲区是合适的？

保持数据在内存，减少磁盘I/O，增加内存代价

若一个页面每秒被访问n次，将它驻留在内存可以节省

<img src="./11.数据库存储.assets/CleanShot 2024-06-09 at 05.22.50@2x.png" alt="CleanShot 2024-06-09 at 05.22.50@2x" style="zoom:50%;" />

保持一个页面在内存的代价

<img src="./11.数据库存储.assets/CleanShot 2024-06-09 at 05.23.03@2x.png" alt="CleanShot 2024-06-09 at 05.23.03@2x" style="zoom:50%;" />

* 5-minute rule：如果一个被随机访问的页面的使用频率超过每5分钟一次，那么它应该被驻留在内存

* 1-minute rule： 如果被顺序访问的页面的使用频率超过每1分钟一次，那么它应该被驻留在内存

<img src="./11.数据库存储.assets/CleanShot 2024-06-09 at 05.23.25@2x.png" alt="CleanShot 2024-06-09 at 05.23.25@2x" style="zoom:50%;" />

## 存储结构

<img src="./11.数据库存储.assets/CleanShot 2024-06-09 at 05.23.37@2x.png" alt="CleanShot 2024-06-09 at 05.23.37@2x" style="zoom:50%;" />

### 页面与区间

* 数据文件被划分成8k的页面
* 每个文件中的页面号都以0开始
* 页面号的形式为（file#：page#），如（3:124）

8个连续页面构成一个区间---64K

* 总是以能被8整除的页面开始

存储分配总是按照区间为单位进行

* 对象每次增长1个区问

I/O可以按页面（8 KB）或者区间（64 KB）来进行

### GAM - 全局分配位图

GAM 是一个页面, 记录文件当中哪些区间已经被分配的页面，可以看成是一个8000个字节的位图，每个位代表一个区间, 差不多64,000位，所以可以表示64,000个区间

表达4GB数据空问，如果文件大于4GB，增加新的GAM页

位0代表区问0，位1代表区间8，位2代表区间16

0：被使用；1：未被使用

### PFS - 空闲页空间

PFS是一个页面, 记录文件中每个页面是否已经被分配以及有多少空闲空间

每一个页面在PFS页中有一个字节对应

* 每个PFS覆盖8088个连续页面（64 MB）
* 页面充满度：0,1-50%，51-80%，81-95%，96-100%

第一个PFS位于文件的第二个页面（page1）

* 以后每8088都是一个PSF页

### IAM - 索引分配位图

IAM是一个页面, 它覆盖的范围与GAM相同, 4GB, 只不过是每一个文件都有一个或几个IAM

如何发现一个特定对象的区间或页面？

* 每个表/索引都至少有一个IAM，记录该对象拥有哪些区间
* IAM覆盖的范围与GAM相同，如果位为1，说明该区间被分配给该对象，如果位为0，说明该区间未被分配给该对象
* 如11000000，说明第一、二个区间被分配给该对象
* 一个对象每占据文件的4G空间，就需要一个IAM，对象的所有IAM构成一个双向链表

### 基本页结构

所有页面包括页面头、页面体、页面槽

<img src="./11.数据库存储.assets/CleanShot 2024-06-09 at 05.33.15@2x.png" alt="CleanShot 2024-06-09 at 05.33.15@2x" style="zoom:50%;" />

#### 基本页结构：页头字段含义

<img src="./11.数据库存储.assets/CleanShot 2024-06-09 at 05.33.32@2x.png" alt="CleanShot 2024-06-09 at 05.33.32@2x" style="zoom:50%;" />

### 数据行结构

<img src="./11.数据库存储.assets/CleanShot 2024-06-09 at 05.33.51@2x.png" alt="CleanShot 2024-06-09 at 05.33.51@2x" style="zoom:50%;" />

### 关系表的行式存储和列式存储

<img src="./11.数据库存储.assets/CleanShot 2024-06-09 at 05.34.57@2x.png" alt="CleanShot 2024-06-09 at 05.34.57@2x" style="zoom:50%;" />

#### 行式存储的特点及其适合的场合

适合取回一条完整记录的场合

* 一条记录的所有字段存储在一起
* 各个字段的异质性导致压缩效果差
* 逻辑上访问单个字段，物理上会把同一记录的其他字段一并返回
* 适合取回一条完整记录的场合 （OLTP）
* 不适合针对单列的聚合分析（OLAP）

#### 列式存储的特点

适合只需要某个属性的查询

<img src="./11.数据库存储.assets/CleanShot 2024-06-09 at 05.35.37@2x.png" alt="CleanShot 2024-06-09 at 05.35.37@2x" style="zoom:50%;" />

#### 列式存储的实现

MonetDB

C-Store & Vertica

## 索引

### B+ 树

<img src="./11.数据库存储.assets/CleanShot 2024-06-15 at 03.54.44@2x.png" alt="CleanShot 2024-06-15 at 03.54.44@2x" style="zoom:50%;" />

每个非叶结点有 $[\mathrm{n} / 2$ ]到 $\mathrm{n}$ 个子女

<img src="./11.数据库存储.assets/CleanShot 2024-06-15 at 03.54.52@2x.png" alt="CleanShot 2024-06-15 at 03.54.52@2x" style="zoom:50%;" />

#### 大小计算

假定一个页 $16 \mathrm{~K}$, 一行 $1 \mathrm{k}$, 一页存放 16 行假定主码为 bigint, 长度8字节, 指针6字节，共14字节，一个页中能存放16384/14=1170 个主码

一棵高度为 2 的 $\mathrm{B}^{+}$树, 能存放 1170*16=18720条这样的数据记录

一个高度为 3 的 $\mathrm{B}^{+}$树可以存放 $1170 * 1170 * 16=21902400$ 条这样的记录

### 哈希索引

### 位图索引

- 针对一些特殊的列建立索引
- 列中的每一个值对应一个向量中的一位
- 向量的长度对应与记录的条数
- 不适合列中值的个数太多的情况

<img src="./11.数据库存储.assets/CleanShot 2024-06-15 at 03.50.14@2x.png" alt="CleanShot 2024-06-15 at 03.50.14@2x" style="zoom:50%;" />

### 多维索引

where 10<A<20 and 10<B<20

#### k-d树

树顶层结点按一维划分，下一层按另一维划分，保持每侧各落入一半数据，直至结点数小于指定值

<img src="./11.数据库存储.assets/CleanShot 2024-06-09 at 05.39.38@2x.png" alt="CleanShot 2024-06-09 at 05.39.38@2x" style="zoom:50%;" />

#### 四叉树

<img src="./11.数据库存储.assets/CleanShot 2024-06-09 at 05.40.04@2x.png" alt="CleanShot 2024-06-09 at 05.40.04@2x" style="zoom:50%;" />

#### R树

高维B树

<img src="./11.数据库存储.assets/CleanShot 2024-06-09 at 05.41.08@2x.png" alt="CleanShot 2024-06-09 at 05.41.08@2x" style="zoom:50%;" />

### LSM树

**并不会像B+树一样，在原数据的位置上修改，而是直接插入新的数据**

**写入磁盘很快, 但是读取有损害, 因为需要在磁盘上遍历树**

B+树的读操作产生磁盘的顺序IO，写操作产生随机磁盘IO

假设要写入10000个随机key，最快的磁盘写入方式是批量顺序写；但这样带来的问题是每次查询都需要遍历整个数 据；如果想获得高磁盘读性能，就需要对数据像B+树那样进行排序，但其写性能又太差，如何权衡？

<img src="./11.数据库存储.assets/CleanShot 2024-06-09 at 05.44.59@2x.png" alt="CleanShot 2024-06-09 at 05.44.59@2x" style="zoom:50%;" />

* 在合并过程中，并不会像B+树一样，在原数据的位置上修改，而是直接插入新的数据，以而避免了随机写
* 当磁盘中的小树合并成一个大树的时候，可以重新排好顺序，使得block连续，优化读性能
* LSM-Tree属于传输型，因为它会使用日志文件和一个内存存储结构把随机写操作转化力顺序写

写入磁盘很快, 但是读取有损害, 因为需要在磁盘上遍历树

对于不存在的数据，如何避免遍历所有集合？引入 Bloom-filter ，当它显示某SSTable中没有目标数据时，就跳过

### 位图索引与B树大小的比较

在数据量很大的时候, B树更好.

因为B树使用内存稳定, 而位图索引在数据量很大的时候需要很多内存

<img src="./11.数据库存储.assets/CleanShot 2024-06-15 at 03.51.36@2x.png" alt="CleanShot 2024-06-15 at 03.51.36@2x" style="zoom:50%;" />
